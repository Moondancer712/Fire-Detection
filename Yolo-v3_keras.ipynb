{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWAuNWXlvwoj",
        "colab_type": "code",
        "outputId": "2585bec3-ffc6-4cf8-f295-642c19becc19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N-UjA5MUM3U",
        "colab_type": "code",
        "outputId": "ba8941ec-4384-45af-f46b-e39068c2ab1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "\n",
        "GoogleDriveDownloader.download_file_from_google_drive(file_id='1Mh90F5-0-lTCqJzwguXY8LV9D5JNEkwu',dest_path=\"./yolo.zip\",unzip=True)\n",
        "!rm yolo.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1Mh90F5-0-lTCqJzwguXY8LV9D5JNEkwu into ./yolo.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFC9LR_XweQz",
        "colab_type": "code",
        "outputId": "a56c668a-9576-4396-ea5c-59483640882b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!pip install keras==2.1.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.1.5 in /usr/local/lib/python3.6/dist-packages (2.1.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyfVNG5uwSFP",
        "colab_type": "code",
        "outputId": "8862e567-22d5-4c19-ca11-3a4902c0a4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd yolo/VOCdevkit/VOC2007"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolo/VOCdevkit/VOC2007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dTrUe9Y6q5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        " \n",
        "trainval_percent = 0.1\n",
        "train_percent = 0.9\n",
        "xmlfilepath = 'Annotations'\n",
        "txtsavepath = 'ImageSets/Main'\n",
        "total_xml = os.listdir(xmlfilepath)\n",
        " \n",
        "num = len(total_xml)\n",
        "list = range(num)\n",
        "tv = int(num * trainval_percent)\n",
        "tr = int(tv * train_percent)\n",
        "trainval = random.sample(list, tv)\n",
        "train = random.sample(trainval, tr)\n",
        " \n",
        "if not os.path.exists(txtsavepath):\n",
        "    print('not exist...{}'.format(txtsavepath))\n",
        "    os.makedirs(txtsavepath)\n",
        " \n",
        "ftrainval = open('ImageSets/Main/trainval.txt', 'w')\n",
        "ftest = open('ImageSets/Main/test.txt', 'w')\n",
        "ftrain = open('ImageSets/Main/train.txt', 'w')\n",
        "fval = open('ImageSets/Main/val.txt', 'w')\n",
        " \n",
        "for i in list:\n",
        "    name = total_xml[i][:-4] + '\\n'\n",
        "    if i in trainval:\n",
        "        ftrainval.write(name)\n",
        "        if i in train:\n",
        "            ftest.write(name)\n",
        "        else:\n",
        "            fval.write(name)\n",
        "    else:\n",
        "        ftrain.write(name)\n",
        " \n",
        "ftrainval.close()\n",
        "ftrain.close()\n",
        "fval.close()\n",
        "ftest.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSMG42t275_d",
        "colab_type": "code",
        "outputId": "0a1d9ebb-8003-452a-ed79-274474d3c5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ennsKOiy9BZs",
        "colab_type": "code",
        "outputId": "adcd96af-72c9-43a2-d911-ef63d8dcf731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd yolo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5PYUeRA9SGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from os import getcwd\n",
        "\n",
        "sets=[('2007', 'train'), ('2007', 'val'), ('2007', 'test')]\n",
        "\n",
        "classes = [\"fire\", \"smoke\"]\n",
        "\n",
        "\n",
        "def convert_annotation(year, image_id, list_file):\n",
        "    in_file = open('VOCdevkit/VOC%s/Annotations/%s.xml'%(year, image_id))\n",
        "    tree=ET.parse(in_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for obj in root.iter('object'):\n",
        "        difficult = obj.find('Difficult').text\n",
        "        cls = obj.find('name').text\n",
        "        if cls not in classes or int(difficult)==1:\n",
        "            continue\n",
        "        cls_id = classes.index(cls)\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
        "        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
        "\n",
        "wd = getcwd()\n",
        "\n",
        "for year, image_set in sets:\n",
        "    image_ids = open('VOCdevkit/VOC%s/ImageSets/Main/%s.txt'%(year, image_set)).read().strip().split()\n",
        "    list_file = open('%s_%s.txt'%(year, image_set), 'w')\n",
        "    for image_id in image_ids:\n",
        "        list_file.write('%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg'%(wd, year, image_id))\n",
        "        convert_annotation(year, image_id, list_file)\n",
        "        list_file.write('\\n')\n",
        "        #print(image_id)\n",
        "    list_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KReo8O9W86rC",
        "colab_type": "code",
        "outputId": "6cb0f937-9fbf-4d11-b025-464021514c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        " \n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix27o5F29KsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _main():\n",
        "    annotation_path = '2007_train.txt'\n",
        "    log_dir = 'logs/000/'\n",
        "    classes_path = 'model_data/voc_classes.txt'\n",
        "    anchors_path = 'model_data/yolo_anchors.txt'\n",
        "    class_names = get_classes(classes_path)\n",
        "    anchors = get_anchors(anchors_path)\n",
        "    input_shape = (416,416) # multiple of 32, hw\n",
        "    model = create_model(input_shape, anchors, len(class_names) )\n",
        "    train(model, annotation_path, input_shape, anchors, len(class_names), log_dir=log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi0n3bIL9ORR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, annotation_path, input_shape, anchors, num_classes, log_dir='logs/'):\n",
        "    model.compile(optimizer='adam', loss={\n",
        "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "    logging = TensorBoard(log_dir=log_dir)\n",
        "    checkpoint = ModelCheckpoint(log_dir + \"ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\",\n",
        "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=1)\n",
        "    batch_size = 10\n",
        "    val_split = 0.1\n",
        "    with open(annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "    np.random.shuffle(lines)\n",
        "    num_val = int(len(lines)*val_split)\n",
        "    num_train = len(lines) - num_val\n",
        "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        " \n",
        "    model.fit_generator(data_generator_wrap(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrap(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=300,\n",
        "            initial_epoch=0)\n",
        "    model.save_weights(log_dir + 'trained_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u6o1ZVJ9Tbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_classes(classes_path):\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpIWbTQO9ZJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_anchors(anchors_path):\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX5DmiQG9Zj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_shape, anchors, num_classes, load_pretrained=False, freeze_body=False,\n",
        "            weights_path='model_data/yolo_weights.h5'):\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        " \n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        " \n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body:\n",
        "            # Do not freeze 3 output layers.\n",
        "            num = len(model_body.layers)-7\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        " \n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})([*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7b7kQhq9Zt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    np.random.shuffle(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            i %= n\n",
        "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i += 1\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llr0n8NB9aE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator_wrap(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LabibWUa9uHH",
        "colab_type": "code",
        "outputId": "65d04e8e-82d2-4737-9952-b9a3aeb24e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    _main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:88: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:91: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1797: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1940: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Create YOLOv3 model with 9 anchors and 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1486: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2836: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Train on 76 samples, val on 8 samples, with batch size 10.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:976: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:963: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/300\n",
            "7/7 [==============================] - 32s 5s/step - loss: 5412.1965 - val_loss: 637212736.0000\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 7s 993ms/step - loss: 1218.2974 - val_loss: 25799116.0000\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 640.8900 - val_loss: 1861522.5000\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 433.9097 - val_loss: 1613.3438\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 311.7258 - val_loss: 707.4068\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 286.0011 - val_loss: 462.6097\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 223.1605 - val_loss: 289.6700\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 179.0145 - val_loss: 237.8344\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 154.3664 - val_loss: 212.4081\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 136.2077 - val_loss: 196.6353\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 126.8322 - val_loss: 163.0378\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 114.8687 - val_loss: 147.8920\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 105.1497 - val_loss: 134.0868\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 97.1701 - val_loss: 712.9766\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 91.9066 - val_loss: 124.5027\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 87.1684 - val_loss: 115.6039\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 82.6781 - val_loss: 328.9523\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 79.4034 - val_loss: 100.5742\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 76.1704 - val_loss: 136.9673\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 71.8777 - val_loss: 88.2365\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 69.7244 - val_loss: 81.0697\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 65.5831 - val_loss: 77.7271\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 63.5720 - val_loss: 74.4318\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 62.4472 - val_loss: 73.5980\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 61.3297 - val_loss: 68.7383\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 58.2257 - val_loss: 70.1116\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 56.5160 - val_loss: 65.5968\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 55.9266 - val_loss: 64.7076\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 54.7902 - val_loss: 60.4544\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 53.5348 - val_loss: 61.3436\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 52.8051 - val_loss: 59.7186\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 52.0864 - val_loss: 57.9106\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 50.3915 - val_loss: 55.9702\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 49.7864 - val_loss: 55.6733\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 48.9056 - val_loss: 55.5449\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 48.0769 - val_loss: 54.0215\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 47.3456 - val_loss: 51.9282\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 46.4820 - val_loss: 51.9478\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 46.3422 - val_loss: 50.0239\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 46.2066 - val_loss: 51.5275\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 46.5287 - val_loss: 51.9258\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 57.1680 - val_loss: 3225.8918\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 46.7528 - val_loss: 279.4601\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 47.7075 - val_loss: 53.8272\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 46.8872 - val_loss: 6139.4751\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 47.6096 - val_loss: 921.5623\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 44.7595 - val_loss: 5260.9346\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 44.0673 - val_loss: 27317.0020\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 42.9212 - val_loss: 7667.9438\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 48.6368 - val_loss: 44.5271\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 42.3039 - val_loss: 43.9015\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 41.2977 - val_loss: 43.2806\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 40.8674 - val_loss: 42.5758\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 40.9253 - val_loss: 44.7959\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 40.3095 - val_loss: 45.2412\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 40.4591 - val_loss: 44.2096\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 45.4591 - val_loss: 40.4235\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 40.7085 - val_loss: 63.5735\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 39.9618 - val_loss: 833.2141\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 40.9103 - val_loss: 847.9543\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 39.6513 - val_loss: 49.6869\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 40.1613 - val_loss: 48.2467\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.2742 - val_loss: 325.9532\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 42.5969 - val_loss: 41.8454\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.6402 - val_loss: 47.6686\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.7083 - val_loss: 111.4701\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.6932 - val_loss: 41.3872\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 36.8306 - val_loss: 43.9764\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.1848 - val_loss: 41.9420\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.5860 - val_loss: 38.8207\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 36.9619 - val_loss: 43.3334\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 37.1335 - val_loss: 42.0956\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.7137 - val_loss: 40.6060\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 64.0898 - val_loss: 761.9790\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 43.4878 - val_loss: 463.9294\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.9920 - val_loss: 69.9580\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 39.0791 - val_loss: 65.9206\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 39.6516 - val_loss: 78.1759\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.8376 - val_loss: 1329.9567\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 37.2996 - val_loss: 319.1995\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 37.4072 - val_loss: 431.5240\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 40.1339 - val_loss: 39.3049\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 36.6353 - val_loss: 38.2596\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 36.1093 - val_loss: 39.7300\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 38.5832 - val_loss: 38.9089\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 36.5107 - val_loss: 42.0280\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 36.1951 - val_loss: 39.0304\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 36.2534 - val_loss: 40.1260\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 35.9613 - val_loss: 40.0483\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 35.5591 - val_loss: 40.3376\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 35.5219 - val_loss: 40.4610\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 35.7634 - val_loss: 40.5226\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 35.0376 - val_loss: 39.2276\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.1883 - val_loss: 38.7878\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 7s 996ms/step - loss: 35.2365 - val_loss: 38.3249\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.9200 - val_loss: 38.5573\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.6243 - val_loss: 41.0291\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.3047 - val_loss: 39.0345\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.9708 - val_loss: 37.5627\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.9244 - val_loss: 38.9006\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.1929 - val_loss: 36.8570\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.5761 - val_loss: 38.3996\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.6962 - val_loss: 37.4961\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.5219 - val_loss: 38.1526\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.7532 - val_loss: 37.7334\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.6814 - val_loss: 37.0618\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.7243 - val_loss: 36.5199\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.2944 - val_loss: 37.2871\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.1342 - val_loss: 36.5340\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.4523 - val_loss: 37.4118\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.1418 - val_loss: 36.4296\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.3200 - val_loss: 36.0780\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.4368 - val_loss: 34.7433\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.0662 - val_loss: 36.2542\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.7322 - val_loss: 35.4438\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.8906 - val_loss: 36.9686\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.3850 - val_loss: 35.5410\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.1640 - val_loss: 35.5783\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.0933 - val_loss: 36.7894\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.8306 - val_loss: 36.2496\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.2495 - val_loss: 36.8562\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.6447 - val_loss: 36.9713\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.5972 - val_loss: 33.9671\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.6808 - val_loss: 34.9076\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.8857 - val_loss: 35.7262\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.2271 - val_loss: 35.3132\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.6355 - val_loss: 33.5568\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.3580 - val_loss: 35.5585\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.3017 - val_loss: 40.1046\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.3961 - val_loss: 34.1986\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.5333 - val_loss: 34.4399\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.0194 - val_loss: 35.4317\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.3809 - val_loss: 33.1799\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.8042 - val_loss: 39.4401\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.2063 - val_loss: 35.1964\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.8649 - val_loss: 34.6318\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.3195 - val_loss: 32.8155\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.8197 - val_loss: 33.5305\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.3229 - val_loss: 34.4536\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.6489 - val_loss: 33.1672\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.6576 - val_loss: 37.6747\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.8254 - val_loss: 818.8567\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.3389 - val_loss: 35843.5938\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.2055 - val_loss: 643417.7500\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.3643 - val_loss: 822793.5625\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.0529 - val_loss: 48054.4297\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.4583 - val_loss: 3810.4260\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.9203 - val_loss: 8730.8193\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.3355 - val_loss: 862.2846\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.8621 - val_loss: 292.1886\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.4847 - val_loss: 3970.3040\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.5491 - val_loss: 243.5176\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.7508 - val_loss: 511.5987\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.6255 - val_loss: 39.8527\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.4872 - val_loss: 268.9503\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.6363 - val_loss: 1543.2223\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.3329 - val_loss: 42.6909\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.7059 - val_loss: 524.9014\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.5754 - val_loss: 33.6478\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.2653 - val_loss: 37.1361\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.1374 - val_loss: 34.3258\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.0613 - val_loss: 34.6916\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.7398 - val_loss: 33.5725\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.8226 - val_loss: 32.7138\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.8097 - val_loss: 36.0141\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.0579 - val_loss: 32.8226\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.6042 - val_loss: 34.8681\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.6828 - val_loss: 33.3693\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.5804 - val_loss: 33.6381\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.4532 - val_loss: 34.8775\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.7560 - val_loss: 33.4632\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.6387 - val_loss: 35.0608\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.5847 - val_loss: 32.7946\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.2739 - val_loss: 32.9155\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.1714 - val_loss: 30.8552\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.6379 - val_loss: 32.8964\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.2368 - val_loss: 31.1911\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.1152 - val_loss: 32.6954\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.5320 - val_loss: 30.7741\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.8560 - val_loss: 33.2362\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 35.2064 - val_loss: 32.7453\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.6189 - val_loss: 86.4957\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.4460 - val_loss: 1880.4325\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.1746 - val_loss: 55549.7617\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.2157 - val_loss: 702.6736\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.0603 - val_loss: 4077.2151\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.5741 - val_loss: 899.7549\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.2668 - val_loss: 38.4158\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.6636 - val_loss: 43.7782\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.3284 - val_loss: 108.0360\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.0633 - val_loss: 60.9890\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.2030 - val_loss: 43.4664\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.4529 - val_loss: 47.3686\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.6550 - val_loss: 33.3050\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 35.7812 - val_loss: 199.2962\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.1177 - val_loss: 160.3171\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.8450 - val_loss: 65.9765\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.7097 - val_loss: 321.3727\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.8258 - val_loss: 1169.2502\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 34.1553 - val_loss: 68.6351\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 42.3072 - val_loss: 5275.9785\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.2172 - val_loss: 172.0146\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 35.9083 - val_loss: 108.6477\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.1623 - val_loss: 42.9294\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.0672 - val_loss: 111.0068\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.0639 - val_loss: 38.6108\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.1519 - val_loss: 42.4520\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 7s 999ms/step - loss: 31.0512 - val_loss: 39.3666\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 33.3066 - val_loss: 41.5672\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.8618 - val_loss: 36.5234\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 7s 998ms/step - loss: 31.4082 - val_loss: 33.9128\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.0082 - val_loss: 36.6589\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.1393 - val_loss: 33.7411\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.3310 - val_loss: 35.4921\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.0507 - val_loss: 34.3652\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.6381 - val_loss: 33.8064\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.9644 - val_loss: 34.5197\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.7256 - val_loss: 36.5108\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.6901 - val_loss: 33.1321\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.0774 - val_loss: 33.9821\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.4600 - val_loss: 32.8506\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.3266 - val_loss: 35.8830\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.7578 - val_loss: 33.3091\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.4708 - val_loss: 34.5549\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 55.7286 - val_loss: 34.8572\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.4495 - val_loss: 36.7554\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.6734 - val_loss: 36.5032\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 7s 997ms/step - loss: 30.8465 - val_loss: 34.6159\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 31.0917 - val_loss: 33.3752\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.9981 - val_loss: 34.2313\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.7435 - val_loss: 33.5280\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.5069 - val_loss: 35.7594\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.0885 - val_loss: 33.6161\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.5096 - val_loss: 32.9541\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.6817 - val_loss: 33.4641\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.8868 - val_loss: 36.0174\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.9730 - val_loss: 32.7704\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 32.7459 - val_loss: 34.4090\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.1174 - val_loss: 33.7137\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.5747 - val_loss: 36.6397\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.3487 - val_loss: 33.4346\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.6585 - val_loss: 33.5871\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.7005 - val_loss: 31.4798\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.5997 - val_loss: 36.4240\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.7035 - val_loss: 31.8873\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.8553 - val_loss: 34.7714\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.6053 - val_loss: 31.6821\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.3311 - val_loss: 31.7826\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.4181 - val_loss: 30.6889\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.4933 - val_loss: 33.3906\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.2221 - val_loss: 32.2140\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.4526 - val_loss: 32.7848\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.9492 - val_loss: 31.5348\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.4749 - val_loss: 32.9209\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.3394 - val_loss: 32.2976\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.5903 - val_loss: 32.9623\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.7666 - val_loss: 31.3815\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.3335 - val_loss: 34.1592\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 7s 997ms/step - loss: 28.4918 - val_loss: 31.4284\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.9963 - val_loss: 33.9931\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 7s 1000ms/step - loss: 29.1124 - val_loss: 31.0248\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.0524 - val_loss: 31.4001\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 30.2894 - val_loss: 30.3540\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.5735 - val_loss: 31.3487\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.7621 - val_loss: 29.6778\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.9128 - val_loss: 33.7379\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.3399 - val_loss: 31.3745\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.1643 - val_loss: 31.8024\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.4222 - val_loss: 30.7167\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.8630 - val_loss: 32.3414\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.3359 - val_loss: 31.3865\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.4180 - val_loss: 30.6117\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.9904 - val_loss: 28.8110\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.4416 - val_loss: 31.7611\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.7420 - val_loss: 30.1290\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.3000 - val_loss: 31.1725\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.2219 - val_loss: 29.2229\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.0674 - val_loss: 31.0099\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.5357 - val_loss: 29.6438\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 27.9687 - val_loss: 30.4763\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.2225 - val_loss: 35.1574\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.2945 - val_loss: 29.5823\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 27.4897 - val_loss: 29.8201\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.8174 - val_loss: 31.7448\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 29.0791 - val_loss: 31.3067\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.6315 - val_loss: 32.3531\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 27.7909 - val_loss: 31.0454\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.2342 - val_loss: 30.4849\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.3956 - val_loss: 28.3865\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 27.7729 - val_loss: 32.9009\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.0835 - val_loss: 27.9055\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.0148 - val_loss: 31.2722\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 27.5703 - val_loss: 28.9378\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.1562 - val_loss: 30.5142\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 7s 991ms/step - loss: 28.2236 - val_loss: 29.8363\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 26.6999 - val_loss: 30.4498\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 27.4591 - val_loss: 28.7040\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 27.7982 - val_loss: 29.5707\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 27.8873 - val_loss: 28.1612\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 7s 1s/step - loss: 28.1431 - val_loss: 31.5482\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}